Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 2588 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.275 seconds (JVM running for 3.125)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 6983.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-182a8f23-8c22-432d-b6a9-5a009c1c1478
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @6072ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @6140ms
Started ServerConnector@2b037cfc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@e042c99{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@26b95b0b{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64fe9da7{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17c2d509{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@245ec1a6{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@38792286{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@665522c2{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3062f9f4{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6f1a80fb{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7d2998d8{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@51a6cc2a{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2123064f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@28cb3a25{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6cfd9a54{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9aa2002{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73d4066e{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a2fa51f{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@22a0d4ea{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10afe71a{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@212dfd39{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7002.
Server created on DESKTOP-AGBUJPR.mshome.net:7002
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7002, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:7002 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7002, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7002, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7002, None)
Started o.s.j.s.ServletContextHandler@27d33393{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@596042df{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@57e1a6cc{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@58b6ff70{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41129e9d{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@559030d0{/static/sql,null,AVAILABLE,@Spark}
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 17356 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.114 seconds (JVM running for 2.821)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 7126.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-e5be7122-88be-40c4-95cf-0fc3fea5f217
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5549ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5593ms
Started ServerConnector@31ceba99{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@7dd611c8{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7e744f43{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a4ccef7{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f7da3d3{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a22bad6{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17c2d509{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1a0b5323{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@245ec1a6{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@38792286{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@665522c2{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3062f9f4{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6f1a80fb{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7d2998d8{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@51a6cc2a{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2123064f{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@28cb3a25{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6cfd9a54{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7c251f90{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5ba26eb0{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@741f8dbe{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7145.
Server created on DESKTOP-AGBUJPR.mshome.net:7145
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7145, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:7145 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7145, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7145, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7145, None)
Started o.s.j.s.ServletContextHandler@68ab0936{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@6225fb59{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71523166{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78dcc3a2{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@33e30abd{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4dec9fa3{/static/sql,null,AVAILABLE,@Spark}
It took 158 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:7145 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:54
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:54
Got job 0 (json at RunSparkTask.scala:54) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:54)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:54), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:7145 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:54) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 150.0525 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 522 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:54) finished in 0.634 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:54, took 0.667297 s
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 5884 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.173 seconds (JVM running for 2.768)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 9729.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-8095a7f2-76d1-41d8-b068-889817a51dfd
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5476ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5519ms
Started ServerConnector@74d3b638{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@1000d54d{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a22bad6{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64fe9da7{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@a2ddf26{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6daf7d37{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@108a46d6{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17690e14{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 9749.
Server created on DESKTOP-AGBUJPR.mshome.net:9749
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 9749, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:9749 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 9749, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 9749, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 9749, None)
Started o.s.j.s.ServletContextHandler@378cfecf{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@3d64c581{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4190bc8a{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2fdf17dc{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@650ae78c{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2cde651b{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 136 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:9749 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:56
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:56
Got job 0 (json at RunSparkTask.scala:56) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:56)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:56), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:9749 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:56) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 132.381 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 480 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:56) finished in 0.576 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:56, took 0.606054 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 12728 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.147 seconds (JVM running for 2.807)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 10012.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-ce32d985-bf3f-4ad9-8b85-4a8fe4daa6a8
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5564ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5608ms
Started ServerConnector@73d3e555{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@1a2909ae{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f7da3d3{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@741f8dbe{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9fc9f91{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 10031.
Server created on DESKTOP-AGBUJPR.mshome.net:10031
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10031, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:10031 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10031, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10031, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10031, None)
Started o.s.j.s.ServletContextHandler@36480b2d{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@474821de{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5ec5ea63{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69d45cca{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6e6d4780{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7ff8a9dc{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 153 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10031 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:59
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:59
Got job 0 (json at RunSparkTask.scala:59) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:59)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:59), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10031 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:59) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 136.2434 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 497 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:59) finished in 0.594 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:59, took 0.624525 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 8688 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.097 seconds (JVM running for 2.71)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 10266.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-0dae1137-8df5-4137-af6e-db51c4df707b
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5408ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5452ms
Started ServerConnector@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@684b31de{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 10285.
Server created on DESKTOP-AGBUJPR.mshome.net:10285
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10285, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:10285 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10285, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10285, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10285, None)
Started o.s.j.s.ServletContextHandler@517a2b0{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@5d97caa4{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@474821de{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5c83ae01{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69d45cca{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7d904ff1{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 152 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10285 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:59
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:59
Got job 0 (json at RunSparkTask.scala:59) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:59)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:59), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10285 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:59) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 130.3553 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 491 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:59) finished in 0.591 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:59, took 0.620158 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 6576 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.098 seconds (JVM running for 2.726)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 10856.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-66228eb9-719f-4603-93d3-e4254786ead6
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5459ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5506ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 10876.
Server created on DESKTOP-AGBUJPR.mshome.net:10876
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10876, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:10876 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10876, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10876, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10876, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@4f94e148{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2cde651b{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7f37b6d9{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@22a10ac6{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@51d719bc{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 149 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10876 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:60
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:60
Got job 0 (json at RunSparkTask.scala:60) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:60)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:60), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10876 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:60) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 134.1454 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 485 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:60) finished in 0.584 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:60, took 0.616180 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 8752 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.132 seconds (JVM running for 2.767)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 11669.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-bbe1605c-5331-476b-9e2b-ab7708eb62da
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5701ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5746ms
Started ServerConnector@31ceba99{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@5d425813{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@11a8042c{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69391e08{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6884f0d9{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@26b95b0b{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@51841ac6{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@435e60ff{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10afe71a{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@212dfd39{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 11689.
Server created on DESKTOP-AGBUJPR.mshome.net:11689
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11689, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:11689 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11689, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11689, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11689, None)
Started o.s.j.s.ServletContextHandler@3cd9aa64{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@6c5ddccd{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6c101cc1{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5d97caa4{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@474821de{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2d64c100{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 160 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11689 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:55
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:55
Got job 0 (json at RunSparkTask.scala:55) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:55)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:55), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11689 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:55) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 135.9912 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 498 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:55) finished in 0.599 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:55, took 0.628495 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 5016 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.121 seconds (JVM running for 2.765)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 12009.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-5f4b83b3-f5a8-49d7-9365-44f1024cea6c
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5476ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5520ms
Started ServerConnector@bbf9e07{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@1702830d{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a4ccef7{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@35eb4a3b{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f7da3d3{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a22bad6{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64fe9da7{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17c2d509{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1a0b5323{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@245ec1a6{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@38792286{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@665522c2{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3062f9f4{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6f1a80fb{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7d2998d8{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@51a6cc2a{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2123064f{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@28cb3a25{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6cfd9a54{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9aa2002{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5ba26eb0{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17d32e9b{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@741f8dbe{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@a2ddf26{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 12028.
Server created on DESKTOP-AGBUJPR.mshome.net:12028
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12028, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:12028 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12028, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12028, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12028, None)
Started o.s.j.s.ServletContextHandler@42b84286{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@1dbd580{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7d0d91a1{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6732726{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3d64c581{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69d45cca{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12028 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:56
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:56
Got job 0 (json at RunSparkTask.scala:56) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:56)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:56), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12028 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:56) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 131.1733 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 486 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:56) finished in 0.581 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:56, took 0.610525 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 5348 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.176 seconds (JVM running for 2.839)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 12364.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-ab20168b-274f-4319-b3a7-1539f50eba9f
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5531ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5574ms
Started ServerConnector@859ea42{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@3e47a03{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10dc7d6{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@716e431d{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a4ccef7{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@35eb4a3b{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6884f0d9{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@26b95b0b{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5cbe2654{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@496a31da{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17d32e9b{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2e6f610d{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 12384.
Server created on DESKTOP-AGBUJPR.mshome.net:12384
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12384, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:12384 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12384, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12384, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12384, None)
Started o.s.j.s.ServletContextHandler@7724704f{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@697a34af{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4c5228e7{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@22752544{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69d23296{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 13016 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.109 seconds (JVM running for 2.713)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 12929.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-790f69ff-30e0-4c55-b745-94c90997fe9a
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5598ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5641ms
Started ServerConnector@44924587{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@3f702946{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f7da3d3{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a22bad6{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@741f8dbe{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@a2ddf26{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9fc9f91{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@108a46d6{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 12950.
Server created on DESKTOP-AGBUJPR.mshome.net:12950
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12950, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:12950 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12950, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12950, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12950, None)
Started o.s.j.s.ServletContextHandler@1f6917fb{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@4784efd9{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@427ae189{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5434e40c{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@514de325{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 142 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 152.2632 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12950 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:61
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:61
Got job 0 (show at RunSparkTask.scala:61) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:61)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:61), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 16.2 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12950 (size: 7.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:61) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 11.3197 ms
Finished task 0.0 in stage 0.0 (TID 0). 1449 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 270 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:61) finished in 0.428 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:61, took 0.457167 s
Code generated in 7.3138 ms
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 11068 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.156 seconds (JVM running for 2.772)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 13309.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-1c92f072-7d50-4fc4-9d9b-84f6e6d70032
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5532ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5576ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 13329.
Server created on DESKTOP-AGBUJPR.mshome.net:13329
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 13329, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:13329 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 13329, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 13329, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 13329, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 146 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 142.6015 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:13329 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:61
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:61
Got job 0 (show at RunSparkTask.scala:61) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:61)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:61), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 16.2 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:13329 (size: 7.3 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:61) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 11.644 ms
Finished task 0.0 in stage 0.0 (TID 0). 1449 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 274 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:61) finished in 0.429 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:61, took 0.458153 s
Code generated in 6.9402 ms
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 9708 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.132 seconds (JVM running for 2.831)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 14125.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-77aa26af-f56f-4bb0-afb9-421c08aa2574
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5579ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5623ms
Started ServerConnector@688d411b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@5aaaa446{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@636bbbbb{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10dc7d6{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7e744f43{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a4ccef7{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@35eb4a3b{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6884f0d9{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@45404d5{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5cbe2654{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5ba26eb0{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17d32e9b{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 14144.
Server created on DESKTOP-AGBUJPR.mshome.net:14144
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14144, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:14144 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14144, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14144, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14144, None)
Started o.s.j.s.ServletContextHandler@37df14d1{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@7f6874f2{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@697a34af{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78b612c6{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@22752544{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3fba233d{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 150 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14144 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:59
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:60
Got job 0 (foreach at RunSparkTask.scala:60) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:60)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[4] at rdd at RunSparkTask.scala:59), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 26.2 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14144 (size: 11.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at rdd at RunSparkTask.scala:59) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 160.2667 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 9.859 ms
Finished task 0.0 in stage 0.0 (TID 0). 1469 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 586 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:60) finished in 0.731 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:60, took 0.757555 s
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 14.6325 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14144 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:65
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:65
Got job 1 (show at RunSparkTask.scala:65) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:65)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[8] at show at RunSparkTask.scala:65), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 16.2 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14144 (size: 7.4 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at RunSparkTask.scala:65) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1406 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 20 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:65) finished in 0.026 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:65, took 0.029101 s
Code generated in 4.549 ms
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 17400 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.122 seconds (JVM running for 2.752)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 14298.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-1cd1af50-ef65-40a3-9b60-6a5127f6572e
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5451ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5509ms
Started ServerConnector@31ceba99{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@5d425813{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@11a8042c{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69391e08{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6884f0d9{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@26b95b0b{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@51841ac6{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@435e60ff{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10afe71a{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@212dfd39{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 14317.
Server created on DESKTOP-AGBUJPR.mshome.net:14317
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14317, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:14317 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14317, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14317, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14317, None)
Started o.s.j.s.ServletContextHandler@3cd9aa64{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@806996{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@257e0827{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@376c7d7d{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3fba233d{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5434e40c{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14317 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:57
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:57
Got job 0 (json at RunSparkTask.scala:57) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:57)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:57), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14317 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:57) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 130.5807 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 480 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:57) finished in 0.576 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:57, took 0.606846 s
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<_corrupt_record: string>
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14317 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from rdd at RunSparkTask.scala:59
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 16420 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.118 seconds (JVM running for 2.812)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 14590.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-01074dbc-6b21-48a6-8521-6046cf38c7cb
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5507ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5552ms
Started ServerConnector@74d3b638{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@1000d54d{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a22bad6{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64fe9da7{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@a2ddf26{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6daf7d37{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@108a46d6{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17690e14{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 14612.
Server created on DESKTOP-AGBUJPR.mshome.net:14612
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14612, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:14612 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14612, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14612, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 14612, None)
Started o.s.j.s.ServletContextHandler@378cfecf{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@427ae189{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@76332405{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@514de325{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43a65cd8{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@24a86066{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
It took 1 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Block broadcast_0 stored as values in memory (estimated size 337.5 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14612 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from json at RunSparkTask.scala:57
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: json at RunSparkTask.scala:57
Got job 0 (json at RunSparkTask.scala:57) with 1 output partitions
Final stage: ResultStage 0 (json at RunSparkTask.scala:57)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:57), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14612 (size: 6.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at RunSparkTask.scala:57) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 130.1213 ms
Finished task 0.0 in stage 0.0 (TID 0). 1952 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 481 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (json at RunSparkTask.scala:57) finished in 0.580 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: json at RunSparkTask.scala:57, took 0.609906 s
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<_corrupt_record: string>
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:14612 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from rdd at RunSparkTask.scala:59
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 15728 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.106 seconds (JVM running for 2.752)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 2125.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-e16424a3-e44e-4cbd-b88e-fb89a35c3633
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5480ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5524ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 2144.
Server created on DESKTOP-AGBUJPR.mshome.net:2144
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 2144, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:2144 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 2144, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 2144, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 2144, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 151 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 139.7112 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:2144 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:63
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:63
Got job 0 (show at RunSparkTask.scala:63) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:63)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:63), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 14.0 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:2144 (size: 7.1 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:63) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 11.53 ms
Finished task 0.0 in stage 0.0 (TID 0). 1449 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 288 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:63) finished in 0.440 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:63, took 0.482525 s
Code generated in 6.4603 ms
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 3200 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.117 seconds (JVM running for 2.832)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 3927.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-d72fbc81-689a-4e82-b043-a6696d6d305d
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5607ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5651ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 3947.
Server created on DESKTOP-AGBUJPR.mshome.net:3947
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3947, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:3947 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3947, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3947, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3947, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 149 ms to list leaf files for 1 paths.
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 1792 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.168 seconds (JVM running for 2.859)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 4877.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-0021692e-8d13-42fa-be93-bc523fb65e62
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5641ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5686ms
Started ServerConnector@859ea42{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@3e47a03{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10dc7d6{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@716e431d{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a4ccef7{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@35eb4a3b{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6884f0d9{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@26b95b0b{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5cbe2654{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@496a31da{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17d32e9b{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2e6f610d{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4899.
Server created on DESKTOP-AGBUJPR.mshome.net:4899
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 4899, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:4899 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 4899, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 4899, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 4899, None)
Started o.s.j.s.ServletContextHandler@7724704f{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@697a34af{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4c5228e7{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@22752544{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69d23296{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
Pushed Filters: IsNotNull(RECODES)
Post-Scan Filters: (size(RECODES#0, true) > 0),isnotnull(RECODES#0)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 146.8423 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:4899 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:64
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:64
Got job 0 (show at RunSparkTask.scala:64) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:64)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:64), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 17.8 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:4899 (size: 7.7 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:64) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 12.515 ms
Code generated in 3.4481 ms
Finished task 0.0 in stage 0.0 (TID 0). 1545 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 284 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:64) finished in 0.362 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:64, took 0.388918 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 7036 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.161 seconds (JVM running for 2.788)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 5475.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-336dd471-3b3b-425e-9823-caca1d2d803d
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5648ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5692ms
Started ServerConnector@bbf9e07{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@6a937336{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69391e08{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@26b95b0b{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@435e60ff{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@212dfd39{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5495.
Server created on DESKTOP-AGBUJPR.mshome.net:5495
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5495, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:5495 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5495, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5495, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5495, None)
Started o.s.j.s.ServletContextHandler@443effcb{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@257e0827{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@21ba2445{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3fba233d{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@514de325{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 146 ms to list leaf files for 1 paths.
spark run result=>	false
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 9692 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.139 seconds (JVM running for 2.816)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 5727.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-6c989eca-a962-42b3-b9d7-631c067571b9
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5684ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5727ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5748.
Server created on DESKTOP-AGBUJPR.mshome.net:5748
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5748, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:5748 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5748, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5748, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5748, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 147 ms to list leaf files for 1 paths.
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 11524 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.131 seconds (JVM running for 2.804)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 5935.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-db44d89d-196b-48b8-87f5-415fc85c7b08
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5500ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5544ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5955.
Server created on DESKTOP-AGBUJPR.mshome.net:5955
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5955, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:5955 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5955, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5955, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5955, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 144 ms to list leaf files for 1 paths.
Pushed Filters: IsNotNull(RECODES)
Post-Scan Filters: (size(RECODES#0, true) > 0),isnotnull(RECODES#0)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 144.7072 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:5955 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:64
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:64
Got job 0 (show at RunSparkTask.scala:64) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:64)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:64), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:5955 (size: 7.3 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:64) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 14.4547 ms
Code generated in 3.9589 ms
Finished task 0.0 in stage 0.0 (TID 0). 1545 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 288 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:64) finished in 0.365 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:64, took 0.393267 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 4380 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.101 seconds (JVM running for 2.754)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 6670.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-030f5a7a-0655-44bf-b5f0-a940686e73a5
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5501ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5545ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 6690.
Server created on DESKTOP-AGBUJPR.mshome.net:6690
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 6690, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:6690 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 6690, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 6690, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 6690, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 133 ms to list leaf files for 1 paths.
spark run result=>	false
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 5860 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.122 seconds (JVM running for 2.73)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 7208.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-70ba3d27-3c13-4029-be28-600753267ebd
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5441ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5484ms
Started ServerConnector@74d3b638{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@1000d54d{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a22bad6{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64fe9da7{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@a2ddf26{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6daf7d37{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@108a46d6{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17690e14{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7230.
Server created on DESKTOP-AGBUJPR.mshome.net:7230
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7230, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:7230 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7230, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7230, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7230, None)
Started o.s.j.s.ServletContextHandler@378cfecf{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@427ae189{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@76332405{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@514de325{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43a65cd8{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@24a86066{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 153 ms to list leaf files for 1 paths.
spark run result=>	false
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 8856 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.098 seconds (JVM running for 2.717)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 7667.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-bf12d393-a9a0-4b22-a20c-fb5f42f7a9bc
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5393ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5436ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7687.
Server created on DESKTOP-AGBUJPR.mshome.net:7687
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7687, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:7687 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7687, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7687, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 7687, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 152 ms to list leaf files for 1 paths.
spark run result=>	false
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 10484 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.112 seconds (JVM running for 2.774)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 8084.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-6189483a-7ef6-473b-99d3-18517b0ca49f
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5470ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5513ms
Started ServerConnector@44924587{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@3f702946{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f7da3d3{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a22bad6{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@741f8dbe{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@a2ddf26{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9fc9f91{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@108a46d6{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 8103.
Server created on DESKTOP-AGBUJPR.mshome.net:8103
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8103, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:8103 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8103, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8103, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8103, None)
Started o.s.j.s.ServletContextHandler@1f6917fb{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@4784efd9{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@427ae189{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5434e40c{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@514de325{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 12884 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.119 seconds (JVM running for 2.798)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 8257.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-81fe732a-aa34-4e28-8be9-7d7e05590dec
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5521ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5566ms
Started ServerConnector@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@684b31de{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 8277.
Server created on DESKTOP-AGBUJPR.mshome.net:8277
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8277, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:8277 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8277, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8277, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8277, None)
Started o.s.j.s.ServletContextHandler@517a2b0{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@21ba2445{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c3820bb{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@187e5235{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43a65cd8{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 146 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: (size(RECODES#0.id, true) > 0),isnotnull(RECODES#0.id)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 149.1722 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:8277 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:67
Planning scan with bin packing, max size: 4196379 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:67
Got job 0 (show at RunSparkTask.scala:67) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:67)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:67), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:8277 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:67) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-2075, partition values: [empty row]
Code generated in 15.7516 ms
Finished task 0.0 in stage 0.0 (TID 0). 1545 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 277 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:67) finished in 0.356 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:67, took 0.382580 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 11224 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.107 seconds (JVM running for 2.754)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 8382.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-22a3697b-646f-4048-bc24-43dd305d2cd8
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5437ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5482ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 8401.
Server created on DESKTOP-AGBUJPR.mshome.net:8401
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8401, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:8401 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8401, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8401, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8401, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: (size(RECODES#0.id, true) > 0),isnotnull(RECODES#0.id)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 144.0261 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:8401 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:67
Planning scan with bin packing, max size: 4194560 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:67
Got job 0 (show at RunSparkTask.scala:67) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:67)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:67), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:8401 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:67) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-256, partition values: [empty row]
Code generated in 14.274 ms
Finished task 0.0 in stage 0.0 (TID 0). 1545 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 272 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:67) finished in 0.347 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:67, took 0.373311 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 4608 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.12 seconds (JVM running for 2.775)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 8600.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-945a7e6d-12c1-42df-bada-d53e6c00f902
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5450ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5492ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 8621.
Server created on DESKTOP-AGBUJPR.mshome.net:8621
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8621, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:8621 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8621, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8621, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 8621, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 157 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: (size(RECODES#0.id, true) > 0),isnotnull(RECODES#0.id)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 142.5824 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:8621 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:67
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:67
Got job 0 (show at RunSparkTask.scala:67) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:67)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:67), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:8621 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:67) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 13.8072 ms
Finished task 0.0 in stage 0.0 (TID 0). 1545 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 271 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:67) finished in 0.347 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:67, took 0.374600 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 1960 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.163 seconds (JVM running for 2.769)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 10677.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-bc244682-083e-4622-8ecc-04d2b8bc900e
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5495ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5539ms
Started ServerConnector@bbf9e07{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@6a937336{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69391e08{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@26b95b0b{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@435e60ff{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@212dfd39{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 10696.
Server created on DESKTOP-AGBUJPR.mshome.net:10696
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10696, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:10696 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10696, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10696, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 10696, None)
Started o.s.j.s.ServletContextHandler@443effcb{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@257e0827{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@21ba2445{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3fba233d{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@514de325{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 159 ms to list leaf files for 1 paths.
Pushed Filters: IsNotNull(RECODES)
Post-Scan Filters: (size(RECODES#0, true) > 0),isnotnull(RECODES#0)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 144.3598 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10696 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:67
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:67
Got job 0 (foreach at RunSparkTask.scala:67) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:67)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:67), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 30.2 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10696 (size: 13.5 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:67) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 22.6841 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 8.8252 ms
Code generated in 3.221 ms
Finished task 0.0 in stage 0.0 (TID 0). 1606 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 351 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:67) finished in 0.469 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:67, took 0.495591 s
Pushed Filters: 
Post-Scan Filters: (size(RECODES#0.id, true) > 0),isnotnull(RECODES#0.id)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 7.3691 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10696 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:68
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:68
Got job 1 (show at RunSparkTask.scala:68) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:68)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:68), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:10696 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:68) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1502 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 17 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:68) finished in 0.024 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:68, took 0.026572 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 17200 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.128 seconds (JVM running for 2.75)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 11124.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-d38ddd36-e950-483e-a409-0be14e5bf28f
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5495ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5538ms
Started ServerConnector@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@684b31de{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 11143.
Server created on DESKTOP-AGBUJPR.mshome.net:11143
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11143, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:11143 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11143, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11143, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11143, None)
Started o.s.j.s.ServletContextHandler@517a2b0{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@21ba2445{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c3820bb{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@187e5235{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43a65cd8{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 158 ms to list leaf files for 1 paths.
Pushed Filters: IsNotNull(RECODES)
Post-Scan Filters: (size(RECODES#0, true) > 0),isnotnull(RECODES#0)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 142.1595 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11143 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:67
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:67
Got job 0 (foreach at RunSparkTask.scala:67) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:67)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:67), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 30.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.6 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11143 (size: 13.6 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:67) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 21.8363 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 9.1167 ms
Code generated in 3.2819 ms
Finished task 0.0 in stage 0.0 (TID 0). 1606 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 350 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:67) finished in 0.467 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:67, took 0.492885 s
Pushed Filters: 
Post-Scan Filters: (size(RECODES#0.id, true) > 0),isnotnull(RECODES#0.id)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 8.0258 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11143 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:68
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:68
Got job 1 (show at RunSparkTask.scala:68) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:68)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:68), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11143 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:68) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1502 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 17 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:68) finished in 0.025 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:68, took 0.027174 s
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 5296 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.114 seconds (JVM running for 2.758)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 11496.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-c2c807f6-f57c-4d37-adc2-fcefa16db619
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5452ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5495ms
Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@63b3ee82{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f172d4a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@67efd2c2{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ede9c7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3dd4a6fa{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f725306{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2412a42b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4715ae33{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fac1d5c{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a2ef072{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2f00f851{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 11516.
Server created on DESKTOP-AGBUJPR.mshome.net:11516
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11516, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:11516 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11516, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11516, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 11516, None)
Started o.s.j.s.ServletContextHandler@1305c126{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@d1d8e1a{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b48e183{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4e682398{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f1a4795{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
Pushed Filters: IsNotNull(RECODES)
Post-Scan Filters: (size(RECODES#0, true) > 0),isnotnull(RECODES#0)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 145.3477 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11516 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:67
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:67
Got job 0 (foreach at RunSparkTask.scala:67) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:67)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:67), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 30.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.6 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11516 (size: 13.6 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:67) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 21.8243 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 8.9279 ms
Code generated in 3.2969 ms
Finished task 0.0 in stage 0.0 (TID 0). 1606 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 350 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:67) finished in 0.467 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:67, took 0.492452 s
Pushed Filters: 
Post-Scan Filters: (size(RECODES#0.id, true) > 0),isnotnull(RECODES#0.id)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 8.1292 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11516 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:68
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:68
Got job 1 (show at RunSparkTask.scala:68) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:68)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:68), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:11516 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:68) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1502 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 18 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:68) finished in 0.025 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:68, took 0.028126 s
Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-AGBUJPR.mshome.net:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 16508 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.144 seconds (JVM running for 2.771)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 12837.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-64dc90f6-56ce-4f6f-8eff-20941fd33176
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5546ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5589ms
Started ServerConnector@859ea42{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@3e47a03{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10dc7d6{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@716e431d{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a4ccef7{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@35eb4a3b{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6884f0d9{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@26b95b0b{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5cbe2654{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@496a31da{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17d32e9b{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2e6f610d{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 12856.
Server created on DESKTOP-AGBUJPR.mshome.net:12856
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12856, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:12856 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12856, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12856, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 12856, None)
Started o.s.j.s.ServletContextHandler@7724704f{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@697a34af{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4c5228e7{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@22752544{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69d23296{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 150 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 147.6833 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12856 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from show at RunSparkTask.scala:66
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:66
Got job 0 (show at RunSparkTask.scala:66) with 1 output partitions
Final stage: ResultStage 0 (show at RunSparkTask.scala:66)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:66), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 14.0 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12856 (size: 7.1 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at RunSparkTask.scala:66) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 11.871 ms
Finished task 0.0 in stage 0.0 (TID 0). 1449 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 275 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (show at RunSparkTask.scala:66) finished in 0.433 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: show at RunSparkTask.scala:66, took 0.461833 s
Code generated in 7.0411 ms
Pushed Filters: IsNotNull(RECODES)
Post-Scan Filters: (size(RECODES#0, true) > 0),isnotnull(RECODES#0)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 12.9658 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12856 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from rdd at RunSparkTask.scala:69
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:69
Got job 1 (foreach at RunSparkTask.scala:69) with 1 output partitions
Final stage: ResultStage 1 (foreach at RunSparkTask.scala:69)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at rdd at RunSparkTask.scala:69), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 30.3 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.6 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12856 (size: 13.6 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at rdd at RunSparkTask.scala:69) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Code generated in 15.255 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 3.0052 ms
Finished task 0.0 in stage 1.0 (TID 1). 1606 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 84 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (foreach at RunSparkTask.scala:69) finished in 0.156 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: foreach at RunSparkTask.scala:69, took 0.159561 s
Pushed Filters: 
Post-Scan Filters: (size(RECODES#0.id, true) > 0),isnotnull(RECODES#0.id)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 10.1515 ms
Block broadcast_4 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_4_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12856 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 4 from show at RunSparkTask.scala:70
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:70
Got job 2 (show at RunSparkTask.scala:70) with 1 output partitions
Final stage: ResultStage 2 (show at RunSparkTask.scala:70)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 2 (MapPartitionsRDD[13] at show at RunSparkTask.scala:70), which has no missing parents
Block broadcast_5 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_5_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:12856 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 5 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at show at RunSparkTask.scala:70) (first 15 tasks are for partitions Vector(0))
Adding task set 2.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 2.0 (TID 2)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
Finished task 0.0 in stage 2.0 (TID 2) in 10 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 2.0, whose tasks have all completed, from pool 
ResultStage 2 (show at RunSparkTask.scala:70) finished in 0.018 s
Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 2: Stage finished
Job 2 finished: show at RunSparkTask.scala:70, took 0.021045 s
Stopped Spark@859ea42{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-AGBUJPR.mshome.net:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 16080 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.11 seconds (JVM running for 2.709)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 1154.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-9f21c7c0-5e72-4a58-a842-a50ad7c76ded
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5478ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5524ms
Started ServerConnector@73d3e555{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@1a2909ae{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f7da3d3{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@741f8dbe{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9fc9f91{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 1175.
Server created on DESKTOP-AGBUJPR.mshome.net:1175
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 1175, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:1175 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 1175, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 1175, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 1175, None)
Started o.s.j.s.ServletContextHandler@36480b2d{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@3c3820bb{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4784efd9{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@187e5235{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5434e40c{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 136 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:1175 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:69
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:69
Got job 0 (foreach at RunSparkTask.scala:69) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:69)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[4] at rdd at RunSparkTask.scala:69), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 26.3 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:1175 (size: 11.4 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at rdd at RunSparkTask.scala:69) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 158.5102 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 9.9681 ms
Finished task 0.0 in stage 0.0 (TID 0). 1469 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 582 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:69) finished in 0.722 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:69, took 0.750306 s
spark run result=>	false
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 9040 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.133 seconds (JVM running for 2.754)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 2467.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-ab465e33-9689-4e9a-b450-af6f0c815013
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5534ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5577ms
Started ServerConnector@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@684b31de{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 2490.
Server created on DESKTOP-AGBUJPR.mshome.net:2490
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 2490, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:2490 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 2490, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 2490, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 2490, None)
Started o.s.j.s.ServletContextHandler@517a2b0{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@21ba2445{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c3820bb{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@187e5235{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43a65cd8{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 155 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 143.3089 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:2490 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:71
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:71
Got job 0 (foreach at RunSparkTask.scala:71) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:71)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 32.4 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:2490 (size: 13.7 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 31.4562 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 8.3671 ms
Finished task 0.0 in stage 0.0 (TID 0). 1494 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 354 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:71) finished in 0.549 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:71, took 0.576641 s
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 8.6446 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:2490 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:72
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:72
Got job 1 (show at RunSparkTask.scala:72) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:72)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 14.0 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:2490 (size: 7.1 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1406 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 15 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:72) finished in 0.022 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:72, took 0.025089 s
Code generated in 3.816 ms
Stopped Spark@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-AGBUJPR.mshome.net:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 16640 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.106 seconds (JVM running for 3.506)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 3012.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-e73a701e-6bcc-4576-99f8-bf381940b121
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @6453ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @6497ms
Started ServerConnector@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@684b31de{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 3032.
Server created on DESKTOP-AGBUJPR.mshome.net:3032
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3032, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:3032 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3032, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3032, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3032, None)
Started o.s.j.s.ServletContextHandler@517a2b0{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@21ba2445{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c3820bb{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@187e5235{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43a65cd8{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 158 ms to list leaf files for 1 paths.
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 139.2019 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:3032 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:71
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:71
Got job 0 (foreach at RunSparkTask.scala:71) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:71)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 32.4 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:3032 (size: 13.7 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 30.3126 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 8.5568 ms
Finished task 0.0 in stage 0.0 (TID 0). 1494 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 354 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:71) finished in 0.552 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:71, took 0.578967 s
Pushed Filters: 
Post-Scan Filters: 
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 8.947 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:3032 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:72
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:72
Got job 1 (show at RunSparkTask.scala:72) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:72)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 14.0 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:3032 (size: 7.1 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1363 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 16 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:72) finished in 0.021 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:72, took 0.024391 s
Code generated in 3.9827 ms
Stopped Spark@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-AGBUJPR.mshome.net:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 1800 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.109 seconds (JVM running for 2.734)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 3920.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-571d802d-5de8-4187-a280-1171b9d232ce
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5423ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5465ms
Started ServerConnector@73d3e555{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@1a2909ae{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5f7da3d3{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71d9cb05{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71945bc0{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@741f8dbe{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9fc9f91{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 3940.
Server created on DESKTOP-AGBUJPR.mshome.net:3940
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3940, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:3940 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3940, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3940, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 3940, None)
Started o.s.j.s.ServletContextHandler@36480b2d{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@3c3820bb{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4784efd9{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@187e5235{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5434e40c{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17461db{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 148 ms to list leaf files for 1 paths.
Pushed Filters: IsNotNull(RECODES)
Post-Scan Filters: (size(RECODES#0, true) > 0),isnotnull(RECODES#0)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 147.3916 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:3940 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:71
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:71
Got job 0 (foreach at RunSparkTask.scala:71) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:71)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 30.5 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:3940 (size: 13.7 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 21.3643 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 9.2184 ms
Code generated in 3.2965 ms
Finished task 0.0 in stage 0.0 (TID 0). 1606 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 349 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:71) finished in 0.464 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:71, took 0.489537 s
Pushed Filters: 
Post-Scan Filters: (size(RECODES#0.id, true) > 0),isnotnull(RECODES#0.id)
Output Data Schema: struct<RECODES: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 7.7501 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:3940 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:72
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:72
Got job 1 (show at RunSparkTask.scala:72) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:72)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:3940 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1545 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 18 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:72) finished in 0.025 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:72, took 0.027222 s
Stopped Spark@73d3e555{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-AGBUJPR.mshome.net:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 17696 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.147 seconds (JVM running for 2.816)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 4604.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-94fbf459-07a1-4b3d-9c42-8f2798f922f1
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5587ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5630ms
Started ServerConnector@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@684b31de{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 4623.
Server created on DESKTOP-AGBUJPR.mshome.net:4623
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 4623, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:4623 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 4623, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 4623, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 4623, None)
Started o.s.j.s.ServletContextHandler@517a2b0{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@21ba2445{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c3820bb{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@187e5235{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43a65cd8{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 147 ms to list leaf files for 1 paths.
Pushed Filters: IsNotNull(RECORDS)
Post-Scan Filters: (size(RECORDS#0, true) > 0),isnotnull(RECORDS#0)
Output Data Schema: struct<RECORDS: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 145.8472 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:4623 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:71
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:71
Got job 0 (foreach at RunSparkTask.scala:71) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:71)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 30.5 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:4623 (size: 13.7 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 21.6125 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Code generated in 9.9702 ms
Code generated in 4.1136 ms
Finished task 0.0 in stage 0.0 (TID 0). 1606 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 358 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:71) finished in 0.478 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:71, took 0.504239 s
Pushed Filters: 
Post-Scan Filters: (size(RECORDS#0.id, true) > 0),isnotnull(RECORDS#0.id)
Output Data Schema: struct<RECORDS: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 8.4558 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:4623 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:72
Planning scan with bin packing, max size: 4194786 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:72
Got job 1 (show at RunSparkTask.scala:72) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:72)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:4623 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-482, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1502 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 16 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:72) finished in 0.025 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:72, took 0.028019 s
Stopped Spark@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-AGBUJPR.mshome.net:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
spark run result=>	true
Starting App using Java 1.8.0_151 on DESKTOP-AGBUJPR with PID 11912 (D:\IdeaProject\gmail\spark_gmail\target\classes started by Machenike in D:\IdeaProject\gmail)
No active profile set, falling back to default profiles: default
Started App in 1.131 seconds (JVM running for 2.776)
Application availability state LivenessState changed to CORRECT
Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
Running Spark version 3.2.0
==============================================================
No custom resources configured for spark.driver.
==============================================================
Submitted application: sql
Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
Limiting resource is cpu
Added ResourceProfile id: 0
Changing view acls to: Machenike,atguigu
Changing modify acls to: Machenike,atguigu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Machenike, atguigu); groups with view permissions: Set(); users  with modify permissions: Set(Machenike, atguigu); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 5583.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Registering BlockManagerMasterHeartbeat
Created local directory at C:\Users\Machenike\AppData\Local\Temp\blockmgr-03129039-aa2a-4656-bdc8-287c135c7010
MemoryStore started with capacity 3.0 GiB
Registering OutputCommitCoordinator
Logging initialized @5436ms to org.sparkproject.jetty.util.log.Slf4jLog
jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_151-b12
Started @5479ms
Started ServerConnector@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@684b31de{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@64b3b1ce{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49ec6a9f{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@103082dd{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@56afdf9a{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@70cccd8f{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77ec6a3d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@36bf84e{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25b52284{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@782be4eb{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d4860f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41fe8e5f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2016f509{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a237731{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a0094c9{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10fda3d0{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f6b687e{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5555ffcf{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c1372d{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@73fb1d7f{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d2f66{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@66f0548d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e86a5a7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65d57e4e{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@23a5818e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-AGBUJPR.mshome.net:4040
Starting executor ID driver on host DESKTOP-AGBUJPR.mshome.net
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 5606.
Server created on DESKTOP-AGBUJPR.mshome.net:5606
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5606, None)
Registering block manager DESKTOP-AGBUJPR.mshome.net:5606 with 3.0 GiB RAM, BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5606, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5606, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-AGBUJPR.mshome.net, 5606, None)
Started o.s.j.s.ServletContextHandler@517a2b0{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
Warehouse path is 'file:/D:/IdeaProject/gmail/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@21ba2445{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c3820bb{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16a9eb2e{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@187e5235{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43a65cd8{/static/sql,null,AVAILABLE,@Spark}
Using an existing SparkSession; some spark core configurations may not take effect.
It took 145 ms to list leaf files for 1 paths.
Pushed Filters: IsNotNull(RECORDS)
Post-Scan Filters: (size(RECORDS#0, true) > 0),isnotnull(RECORDS#0)
Output Data Schema: struct<RECORDS: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 150.5738 ms
Block broadcast_0 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_0_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:5606 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 0 from rdd at RunSparkTask.scala:71
Planning scan with bin packing, max size: 4194519 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: foreach at RunSparkTask.scala:71
Got job 0 (foreach at RunSparkTask.scala:71) with 1 output partitions
Final stage: ResultStage 0 (foreach at RunSparkTask.scala:71)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71), which has no missing parents
Block broadcast_1 stored as values in memory (estimated size 30.5 KiB, free 3.0 GiB)
Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 3.0 GiB)
Added broadcast_1_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:5606 (size: 13.7 KiB, free: 3.0 GiB)
Created broadcast 1 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at rdd at RunSparkTask.scala:71) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 0.0 (TID 0)
Code generated in 22.4095 ms
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-215, partition values: [empty row]
Code generated in 9.2442 ms
Code generated in 3.2566 ms
Finished task 0.0 in stage 0.0 (TID 0). 1606 bytes result sent to driver
Finished task 0.0 in stage 0.0 (TID 0) in 346 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (foreach at RunSparkTask.scala:71) finished in 0.463 s
Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 0: Stage finished
Job 0 finished: foreach at RunSparkTask.scala:71, took 0.490925 s
Pushed Filters: 
Post-Scan Filters: (size(RECORDS#0.id, true) > 0),isnotnull(RECORDS#0.id)
Output Data Schema: struct<RECORDS: array<struct<id:string,country_id:string,code:string,name:string,cname:string,lower_name:string>>>
Code generated in 7.9763 ms
Block broadcast_2 stored as values in memory (estimated size 337.4 KiB, free 3.0 GiB)
Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 3.0 GiB)
Added broadcast_2_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:5606 (size: 32.4 KiB, free: 3.0 GiB)
Created broadcast 2 from show at RunSparkTask.scala:72
Planning scan with bin packing, max size: 4194519 bytes, open cost is considered as scanning 4194304 bytes.
Starting job: show at RunSparkTask.scala:72
Got job 1 (show at RunSparkTask.scala:72) with 1 output partitions
Final stage: ResultStage 1 (show at RunSparkTask.scala:72)
Parents of final stage: List()
Missing parents: List()
Submitting ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72), which has no missing parents
Block broadcast_3 stored as values in memory (estimated size 16.7 KiB, free 3.0 GiB)
Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.0 GiB)
Added broadcast_3_piece0 in memory on DESKTOP-AGBUJPR.mshome.net:5606 (size: 7.6 KiB, free: 3.0 GiB)
Created broadcast 3 from broadcast at DAGScheduler.scala:1427
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at show at RunSparkTask.scala:72) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks resource profile 0
Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-AGBUJPR.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
Running task 0.0 in stage 1.0 (TID 1)
Reading File path: file:///F:/Desktop/sparkdata/world-area-master/world-area-master/children/json/area.json, range: 0-215, partition values: [empty row]
Finished task 0.0 in stage 1.0 (TID 1). 1538 bytes result sent to driver
Finished task 0.0 in stage 1.0 (TID 1) in 15 ms on DESKTOP-AGBUJPR.mshome.net (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at RunSparkTask.scala:72) finished in 0.022 s
Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
Killing all running tasks in stage 1: Stage finished
Job 1 finished: show at RunSparkTask.scala:72, took 0.025461 s
Code generated in 4.8144 ms
Stopped Spark@2b289ac9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-AGBUJPR.mshome.net:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
spark run result=>	true
